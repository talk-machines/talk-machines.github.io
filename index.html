<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>TalkWithMachines: Enhancing Human-Robot Interaction</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      margin: 0;
      padding: 0;
      color: #333;
    }
    h1 {
      font-size: 2.5em;
      margin-top: 20px;
    }
    h3 {
      font-size: 1.5em;
      color: #555;
    }
    .authors {
      font-size: 1em;
      color: #777;
      margin: 20px 0;
    }
    .icons img {
      width: 60px;
      margin: 10px;
      transition: transform 0.2s;
    }
    .icons img:hover {
      transform: scale(1.1);
    }
    .content {
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
      line-height: 1.6;
    }
    .footer img {
      width: 80px;
      margin: 15px;
    }
    .footer {
      margin-top: 40px;
    }
    .disclaimer {
      font-size: 0.8em;
      color: #999;
      margin-top: 40px;
    }
  </style>
</head>
<body>

  <header>
    <h1>TalkWithMachines</h1>
    <h3>Enhancing Human-Robot Interaction Through Large/Vision Language Models</h3>
    <p class="authors">
      <em>Ammar N. Abbas, Csaba Beleznai</em><br>
      Technological University Dublin, AIT Austrian Institute of Technology<br>
      <a href="mailto:ammar.abbas@tudublin.ie">ammar.abbas@tudublin.ie</a>, <a href="mailto:csaba.beleznai@ait.ac.at">csaba.beleznai@ait.ac.at</a>
    </p>
  </header>

  <section class="icons">
    <a href="talk_machines/assets/paper.pdf"><img src="talk_machines/assets/paper_icon.png" alt="Paper" title="Paper"></a>
    <a href="assets/video.mp4"><img src="assets/video_icon.png" alt="Video" title="Video"></a>
    <a href="https://example.com/blogpost"><img src="assets/blog_icon.png" alt="Blogpost" title="Blogpost"></a>
    <a href="https://github.com/username/repository"><img src="assets/code_icon.png" alt="Code" title="Code"></a>
    <a href="https://example.com/demo"><img src="assets/demo_icon.png" alt="Demo" title="Demo"></a>
  </section>

  <section class="content">
    <h2>Project Overview</h2>
    <p>This project investigates how Large Language Models (LLMs) and Vision Language Models (VLMs) can enhance robotic control, perception, and situational awareness in human-robot interaction.</p>

    <h2>Methodology</h2>
    <p><strong>Framework Overview:</strong></p>
    <img src="assets/diagram.png" alt="Framework Diagram" width="80%">
    <ul>
      <li><strong>Language Processing:</strong> Using LLMs to translate natural language commands to robotic actions.</li>
      <li><strong>Perception and Control:</strong> Integrating VLMs for enhanced object detection and task execution.</li>
    </ul>

    <h2>Experiment Results</h2>
    <h3>Baseline Control</h3>
    <p><strong>Goal:</strong> Test low-level grasping and obstacle avoidance.</p>
    <p><strong>Result:</strong> High success rate with low error in task execution.</p>

    <h3>Supplementary Materials</h3>
    <p><a href="assets/video.mp4">Project Video Overview</a> | <a href="assets/paper.pdf">Full Paper</a></p>
  </section>

  <footer class="footer">
    <p>Affiliations</p>
    <a href="https://www.tudublin.ie/"><img src="assets/tudublin_logo.png" alt="TU Dublin"></a>
    <a href="https://www.ait.ac.at/"><img src="assets/ait_logo.png" alt="AIT Austrian Institute of Technology"></a>
  </footer>

  <p class="disclaimer">* Icons and resources are placeholders. Replace URLs and paths with your actual resources.</p>

</body>
</html>
